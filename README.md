# ğŸŒ‰ Bridge Monitoring Streaming Pipeline  
### Declarative Pipeline â€¢ Lakeflow â€¢ Medallion Architecture

---

## ğŸ‡¬ğŸ‡§ English Version

## ğŸ“Œ Overview
This project implements a **realâ€‘time bridge monitoring system** using a **Declarative Pipeline** built with **Lakeflow** and the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold).  
The pipeline ingests streaming sensor data (temperature, tilt, vibration), processes it through structured transformation layers, and produces enriched metrics for monitoring structural health.

The repository includes:
- Python scripts for each transformation layer  
- SQL queries for materialized views  
- A Databricks Lakeflow streaming pipeline  
- A visual pipeline diagram  

---

## ğŸ—ï¸ Architecture

### ğŸ”¹ **Declarative Pipeline (Lakeflow)**
The pipeline is defined declaratively:  
- You describe **what** each table should contain  
- Lakeflow handles **how** to compute it  
- Automatic orchestration, dependency resolution, and incremental updates

### ğŸ¥‰ Bronze Layer â€” Raw Streaming Data
Files:
- `00_data_generator.py`  
- `01_bronze_processing.py`  

Responsibilities:
- Ingest raw sensor streams (temperature, tilt, vibration)  
- Store unprocessed data in Bronze tables  
- Preserve original schema and timestamps  

### ğŸ¥ˆ Silver Layer â€” Cleaned & Standardized Data
File:
- `02_silver_processing.py`  

Responsibilities:
- Clean and standardize sensor data  
- Normalize schemas  
- Remove corrupt or incomplete records  
- Prepare data for metric computation  

### ğŸ¥‡ Gold Layer â€” Enriched Metrics
File:
- `03_gold_processing.py`  

Responsibilities:
- Compute aggregated bridge metrics  
- Join with metadata  
- Produce analyticsâ€‘ready tables for dashboards and alerts  

---

## ğŸ”„ Lakeflow Streaming Pipeline
The Databricks pipeline processes the following tables in real time:

| Table Name          | Description                          |
|---------------------|--------------------------------------|
| `bridge_temperature` | Temperature sensor stream            |
| `bridge_tilt`        | Tilt sensor stream                   |
| `bridge_vibration`   | Vibration sensor stream              |
| `bridge_metadata`    | Static metadata (bridge info)        |
| `bridge_metrics`     | Final enriched metrics (Gold layer)  |

Each table is automatically refreshed and incrementally updated.

---

## ğŸ§° Technologies Used
- **Databricks Lakeflow** (Declarative Pipelines)  
- **Python** (ETL scripts)  
- **SQL** (Materialized views & queries)  
- **Medallion Architecture**  
- **Streaming data processing**  
- **Realâ€‘time sensor ingestion**  

---

## ğŸ¯ Objectives
- Build a fully declarative, maintainable streaming pipeline  
- Monitor bridge health using realâ€‘time sensor data  
- Apply Medallion Architecture best practices  
- Produce enriched metrics for dashboards and alerting systems  

---


---

---

# ğŸ‡«ğŸ‡· Version FranÃ§aise

## ğŸ“Œ AperÃ§u
Ce projet met en place un **systÃ¨me de surveillance de pont en temps rÃ©el** grÃ¢ce Ã  un **pipeline dÃ©claratif** utilisant **Lakeflow** et lâ€™**architecture Medallion** (Bronze â†’ Silver â†’ Gold).  
Le pipeline ingÃ¨re des flux de capteurs (tempÃ©rature, inclinaison, vibration), les transforme en couches structurÃ©es et produit des mÃ©triques enrichies pour surveiller lâ€™Ã©tat structurel du pont.

Le dÃ©pÃ´t contient :
- Des scripts Python pour chaque couche  
- Des requÃªtes SQL  
- Un pipeline Lakeflow en streaming  
- Un schÃ©ma visuel du pipeline  

---

## ğŸ—ï¸ Architecture

### ğŸ”¹ **Pipeline DÃ©claratif (Lakeflow)**
Le pipeline est dÃ©fini de maniÃ¨re dÃ©clarative :  
- Vous dÃ©crivez **ce que** chaque table doit contenir  
- Lakeflow gÃ¨re **comment** la calculer  
- Orchestration automatique et mises Ã  jour incrÃ©mentales

### ğŸ¥‰ Couche Bronze â€” DonnÃ©es Brutes en Streaming
Fichiers :
- `00_data_generator.py`  
- `01_bronze_processing.py`  

RÃ´le :
- IngÃ©rer les flux bruts des capteurs  
- Stocker les donnÃ©es sans transformation  
- PrÃ©server le schÃ©ma original  

### ğŸ¥ˆ Couche Silver â€” DonnÃ©es NettoyÃ©es
Fichier :
- `02_silver_processing.py`  

RÃ´le :
- Nettoyer et standardiser les donnÃ©es  
- Normaliser les schÃ©mas  
- Retirer les enregistrements corrompus  
- PrÃ©parer les donnÃ©es pour les mÃ©triques  

### ğŸ¥‡ Couche Gold â€” DonnÃ©es Enrichies
Fichier :
- `03_gold_processing.py`  

RÃ´le :
- Calculer les mÃ©triques agrÃ©gÃ©es  
- Joindre les donnÃ©es avec les mÃ©tadonnÃ©es  
- Produire des tables prÃªtes pour la BI et les alertes  

---

## ğŸ”„ Pipeline Lakeflow en Streaming
Le pipeline traite en continu les tables suivantes :

| Nom de Table          | Description                           |
|-----------------------|----------------------------------------|
| `bridge_temperature`  | Flux de tempÃ©rature                    |
| `bridge_tilt`         | Flux dâ€™inclinaison                     |
| `bridge_vibration`    | Flux de vibration                      |
| `bridge_metadata`     | MÃ©tadonnÃ©es statiques                  |
| `bridge_metrics`      | MÃ©triques enrichies (couche Gold)      |

Chaque table est mise Ã  jour automatiquement et de maniÃ¨re incrÃ©mentale.

---

## ğŸ§° Technologies UtilisÃ©es
- **Databricks Lakeflow**  
- **Python**  
- **SQL**  
- **Architecture Medallion**  
- **Traitement de donnÃ©es en streaming**  
- **Ingestion de capteurs en temps rÃ©el**  

---

## ğŸ¯ Objectifs
- Construire un pipeline dÃ©claratif et maintenable  
- Surveiller lâ€™Ã©tat dâ€™un pont en temps rÃ©el  
- Appliquer les bonnes pratiques de lâ€™architecture Medallion  
- Produire des mÃ©triques enrichies pour la BI et les alertes  

---

## ğŸ“ Structure du DÃ©pÃ´t
